# LLM Test-Modus Setup ğŸ§ª

## âœ… Test-Modus ist jetzt aktiv!

Der LLM Feedback Prototyp lÃ¤uft jetzt im **Test-Modus** ohne echte API Keys. Das System erkennt automatisch, dass keine gÃ¼ltigen API Keys vorhanden sind und aktiviert Demo-Responses.

## ğŸ” Status PrÃ¼fen

**Backend Status:**
```powershell
Invoke-WebRequest -UseBasicParsing http://localhost:5000/api/llm/status
```

**Erwartete Antwort:**
```json
{
  "llmAvailable": false,
  "message": "ğŸ§ª Test-Modus aktiv - Demo-Responses", 
  "model": "gpt-4o-mini",
  "provider": "openai",
  "status": "test-mode",
  "testMode": true
}
```

## ğŸ¯ Was der Test-Modus bietet

### Frontend (LLMFeedbackPrototype.jsx)
- âœ… "ğŸ§ª Test-Modus" Anzeige im Header
- âœ… VollstÃ¤ndige UI-FunktionalitÃ¤t 
- âœ… Realistische Mock-Responses fÃ¼r alle Segmente
- âœ… Chat-System funktioniert komplett
- âœ… Keine API-Kosten

### Backend (llm_service.py)
- âœ… Automatische Erkennung von Beispiel-Keys (`your_openai_api_key_here`)
- âœ… Realistische Demo-Responses mit `ğŸ§ª [TEST-MODUS]` Prefix
- âœ… Alle LLM Endpoints funktionieren (`/api/llm/feedback`, `/api/llm/status`)
- âœ… Fallback zu Mock-Data bei jedem API Call

## ğŸš€ Testen im Browser

1. **Ã–ffne die App:** http://localhost oder http://localhost:80
2. **Gehe zur PersonalizationPage**
3. **Klicke "LLM Prototyp"** 
4. **Erwarte:**
   - Header zeigt "ğŸ§ª Test-Modus - Test-Modus aktiv - Demo-Responses"
   - Segmente werden geladen mit Demo-Feedback
   - Chat funktioniert mit Mock-Responses

## âš™ï¸ Test-Modus Konfiguration

Der Test-Modus wird automatisch aktiviert wenn:
- Kein `OPENAI_API_KEY` gesetzt ist
- Oder `OPENAI_API_KEY=your_openai_api_key_here` (Beispiel-Key)
- Oder `LLM_TEST_MODE=force` in .env

### Manuell steuern (.env):
```bash
# Auto-Modus (empfohlen)
LLM_TEST_MODE=auto

# Test-Modus erzwingen (auch mit echten Keys)  
LLM_TEST_MODE=force

# Test-Modus deaktivieren (Fehler ohne Keys)
LLM_TEST_MODE=disabled
```

## ğŸ”„ Auf echte API Keys umstellen

Wenn du spÃ¤ter echte API Keys verwenden mÃ¶chtest:

1. **OpenAI Setup:**
   ```bash
   # In .env ersetzen:
   OPENAI_API_KEY=sk-proj-dein-echter-key-hier
   ```

2. **Container neu starten:**
   ```powershell
   docker-compose restart backend
   ```

3. **Status prÃ¼fen:**
   ```powershell
   Invoke-WebRequest -UseBasicParsing http://localhost:5000/api/llm/status
   ```
   Erwarte: `"status": "ready", "testMode": false`

## ğŸ“ Demo-Response Beispiele

Der Test-Modus generiert realistische Antworten:

**Segment 1 (Good):**
> ğŸ§ª [TEST-MODUS] Fantastisch! In diesem Segment zeigst du schon eine sehr gute Kontrolle Ã¼ber Rhythmus und Dynamik. Deine Phrasierung ist ausdrucksvoll und musikalisch durchdacht.

**Segment 2 (Neutral):**  
> ğŸ§ª [TEST-MODUS] Hier sehe ich sowohl StÃ¤rken als auch Verbesserungspotential. Die Grundtechnik stimmt, aber wir kÃ¶nnten noch an der PrÃ¤zision arbeiten. Was denkst du selbst Ã¼ber diesen Abschnitt?

**Segment 3 (Critical):**
> ğŸ§ª [TEST-MODUS] Das ist ein wichtiger Lernbereich! Hier kÃ¶nnen wir gemeinsam viel erreichen. Lass uns gezielt an der Intonation und dem Timing arbeiten. Hast du Fragen zu diesem Teil?

## âœ¨ Bereit zum Testen!

Das System ist jetzt perfekt konfiguriert fÃ¼r Entwicklung und Demos ohne API-Kosten. Alle LLM Features sind verfÃ¼gbar und funktionieren mit realistischen Mock-Responses! ğŸµğŸ¤–